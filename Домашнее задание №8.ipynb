{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf6f873",
   "metadata": {},
   "source": [
    "# Домашнее задание № 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4bd487",
   "metadata": {},
   "source": [
    "## Задание 1 (4 балла) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4c4f87",
   "metadata": {},
   "source": [
    "Обучите 7 моделей для задачи классификации текста (датасет - lenta_40k ). А именно:  \n",
    "1) модель с 1 GRU слоем;   \n",
    "2) модель с 1 LSTM слоем    \n",
    "3) модель с 1 GRU и 1 LSTM слоем  \n",
    "4) модель с 1 BIGRU и 2 LSTM слоями  \n",
    "5) модель с 5 GRU слоями и 3 LSTM слоями  \n",
    "6) модель 1 BIGRU и 1 BILSTM слоями, причем так чтобы модели для forward и backward прохода отличались   \n",
    "7) модель, где последовательно идут слои: LSTM, GRU, BILSTM, BIGRU, GRU, LSTM  \n",
    "\n",
    "\n",
    "Параметр units и размер эмбединга можете задать любой. Оцените качество каждой модели и определите победителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83db6635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0817f93e",
   "metadata": {},
   "source": [
    "__Возьмем небольшой кусок датасета lenta.ru__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50362f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('lenta_40k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6676dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка нам тут особо не важна\n",
    "def preprocess(text):\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [token.strip(punctuation) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f7de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для рассчёта f-меры возьмём функцию из stackoverflow, предложенную на паре \n",
    "from tensorflow.keras import backend as K\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f399a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем словарь, фильтруем, чтобы он был адекватного размера и переводим токены в индексы\n",
    "vocab = Counter()\n",
    "\n",
    "for text in data.text:\n",
    "    vocab.update(preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c25f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# отфильтрованный словарь\n",
    "filtered_vocab = set()\n",
    "\n",
    "for word in vocab:\n",
    "    if vocab[word] > 30:\n",
    "        filtered_vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df6b1dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# индексируем слова\n",
    "word2id = {'PAD':0, 'UNK':1}\n",
    "\n",
    "for word in filtered_vocab:\n",
    "    word2id[word] = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5391eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {i:word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ae4bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переводим тексты в последовательности индексов\n",
    "X = []\n",
    "\n",
    "for text in data.text:\n",
    "    tokens = preprocess(text)\n",
    "    ids = [word2id.get(token, 1) for token in tokens]\n",
    "    X.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2563cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN_LEN = np.median([len(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "667ee7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = int(MEAN_LEN + 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17bde0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# паддинг\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "384ead3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i:label for i, label in enumerate(set(data.topic.values))}\n",
    "label2id = {l:i for i, l in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "006c0773",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical([label2id[label] for label in data.topic.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f400787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим стратификацию, т.к. в данных у нас дисбаланс классов\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03db817b",
   "metadata": {},
   "source": [
    "__Создадим требуемые модели__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd626fa8",
   "metadata": {},
   "source": [
    "1) модель с 1 GRU слоем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a0edc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
    "\n",
    "gru_layer = tf.keras.layers.GRU(128, return_sequences=False)(embeddings)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(gru_layer)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_1.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d06215",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=1000,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb89d146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score модели с 1 GRU слоем: 0.9356775283813477\n"
     ]
    }
   ],
   "source": [
    "model_1_score = model_1.history.history['f1'][-1]\n",
    "print(\"f-score модели с 1 GRU слоем:\", model_1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d0a913",
   "metadata": {},
   "source": [
    "2) модель с 1 LSTM слоем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "217b546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
    "\n",
    "lstm_layer = tf.keras.layers.LSTM(128, return_sequences=False)(embeddings)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(lstm_layer)\n",
    "\n",
    "model_2 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_2.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=1000,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdafeef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score модели с 1 LSTM слоем: 0.9011369943618774\n"
     ]
    }
   ],
   "source": [
    "model_2_score = model_2.history.history['f1'][-1]\n",
    "print(\"f-score модели с 1 LSTM слоем:\", model_2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450f5c04",
   "metadata": {},
   "source": [
    "3) модель с 1 GRU и 1 LSTM слоем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f817e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
    "\n",
    "lstm_1 = tf.keras.layers.LSTM(128, return_sequences=True)(embeddings)\n",
    "lstm_2 = tf.keras.layers.GRU(128, return_sequences=False)(lstm_1)\n",
    "\n",
    "dense = tf.keras.layers.Dense(64, activation='relu')(lstm_2)\n",
    "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(dense)\n",
    "\n",
    "model_3 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_3.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8db2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=1000,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f3ac149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score модели с 1 GRU и 1 LSTM слоем: 0.9521448612213135\n"
     ]
    }
   ],
   "source": [
    "model_3_score = model_3.history.history['f1'][-1]\n",
    "print(\"f-score модели с 1 GRU и 1 LSTM слоем:\", model_3_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ae4b1",
   "metadata": {},
   "source": [
    "4) модель с 1 BIGRU и 2 LSTM слоями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e3745b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
    "\n",
    "bigru_layer = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(embeddings)\n",
    "lstm_layer_1 = tf.keras.layers.LSTM(128, return_sequences=True)(bigru_layer)\n",
    "lstm_layer_2 = tf.keras.layers.LSTM(128, return_sequences=False)(lstm_layer_1)\n",
    "\n",
    "dense = tf.keras.layers.Dense(64, activation='relu')(lstm_layer_2)\n",
    "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(dense)\n",
    "\n",
    "model_4 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_4.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f2e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=1000,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f6fa3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score модели с 1 BIGRU и 2 LSTM слоями: 0.8436391353607178\n"
     ]
    }
   ],
   "source": [
    "model_4_score = model_4.history.history['f1'][-1]\n",
    "print(\"f-score модели с 1 BIGRU и 2 LSTM слоями:\", model_4_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b1bcbe",
   "metadata": {},
   "source": [
    "5) модель с 5 GRU слоями и 3 LSTM слоями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea8a436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
    "\n",
    "gru_1 = tf.keras.layers.GRU(128, return_sequences=True)(embeddings)\n",
    "gru_2 = tf.keras.layers.GRU(128, return_sequences=True)(gru_1)\n",
    "gru_3 = tf.keras.layers.GRU(128, return_sequences=True)(gru_2)\n",
    "gru_4 = tf.keras.layers.GRU(128, return_sequences=True)(gru_3)\n",
    "gru_5 = tf.keras.layers.GRU(128, return_sequences=True)(gru_4)\n",
    "\n",
    "lstm_1 = tf.keras.layers.LSTM(128, return_sequences=True)(gru_5)\n",
    "lstm_2 = tf.keras.layers.LSTM(128, return_sequences=True)(lstm_1)\n",
    "lstm_3 = tf.keras.layers.LSTM(128, return_sequences=False)(lstm_2)\n",
    "\n",
    "dense = tf.keras.layers.Dense(64, activation='relu')(lstm_3)\n",
    "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(dense)\n",
    "\n",
    "model_5 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_5.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee39be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=1000,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dce8915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score модели с 5 BIGRU и 3 LSTM слоями: 0.0\n"
     ]
    }
   ],
   "source": [
    "model_5_score = model_5.history.history['f1'][-1]\n",
    "print(\"f-score модели с 5 BIGRU и 3 LSTM слоями:\", model_5_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6375970b",
   "metadata": {},
   "source": [
    "6) модель с 1 BIGRU и 1 BILSTM слоями, причем так чтобы модели для forward и backward прохода отличались:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47980a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
    "\n",
    "bigru_bilstm = tf.keras.layers.Bidirectional(\n",
    "                                       tf.keras.layers.GRU(128, return_sequences=False),\n",
    "                        backward_layer=tf.keras.layers.LSTM(128, return_sequences=False, \n",
    "                                                            go_backwards=True))(embeddings)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(bigru_bilstm)\n",
    "model_6 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model_6.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb398298",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=1000,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a44af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score модели с 1 BIGRU и 1 BILSTM слоями: 0.8516635623931885\n"
     ]
    }
   ],
   "source": [
    "model_6_score = model_6.history.history['f1'][-1]\n",
    "print(\"f-score модели с 1 BIGRU и 1 BILSTM слоями:\", model_6_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a69df0",
   "metadata": {},
   "source": [
    "7) модель, где последовательно идут слои: LSTM, GRU, BILSTM, BIGRU, GRU, LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3788e43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
    "\n",
    "lstm_1 = tf.keras.layers.LSTM(128, return_sequences=True)(embeddings)\n",
    "gru_1 = tf.keras.layers.GRU(128, return_sequences=True)(lstm_1)\n",
    "bilstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(gru_1)\n",
    "bigru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(bilstm)\n",
    "gru_2 = tf.keras.layers.GRU(128, return_sequences=True)(bigru)\n",
    "lstm_2_final = tf.keras.layers.LSTM(128, return_sequences=False)(gru_2)\n",
    "\n",
    "dense = tf.keras.layers.Dense(64, activation='relu')(lstm_2_final)\n",
    "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(dense)\n",
    "\n",
    "model_7 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model_7.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=1000,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7a359e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score модели, где последовательно идут слои: LSTM, GRU, BILSTM, BIGRU, GRU, LSTM: 0.6749071973800659\n"
     ]
    }
   ],
   "source": [
    "model_7_score = model_7.history.history['f1'][-1]\n",
    "print(\"f-score модели, где последовательно идут слои: LSTM, GRU, BILSTM, BIGRU, GRU, LSTM:\", model_7_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd16711",
   "metadata": {},
   "source": [
    "__Лучше всего себя показала модель с  с 1 GRU и 1 LSTM слоем__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d6eea",
   "metadata": {},
   "source": [
    "## Задание 2 (6 баллов)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2c07cf",
   "metadata": {},
   "source": [
    "На данных википедии (wikiann) обучите 2 модели:  \n",
    "1) модель в которой будут использованы предобученные эмбединги слов и несколько BILSTM слоев. \n",
    "1) модель в которой будут использованы предобученные эмбединги слов и несколько BIGRU слоев. \n",
    "\n",
    "Сравните качество по метрикам. Также придумайте несколько сложных примеров и проверьте, какие сущности определяет каждая из моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d451813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b4e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8035db14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb75f77db1b420f9df5240d7133b3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e4c3a3e7594135a44615ad0ccff9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/12.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann/ru (download: 223.17 MiB, generated: 9.87 MiB, post-processed: Unknown size, total: 233.04 MiB) to C:\\Users\\tanbe\\.cache\\huggingface\\datasets\\wikiann\\ru\\1.1.0\\4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42eb5a378f534d3dabd8e0e83424d87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/234M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann downloaded and prepared to C:\\Users\\tanbe\\.cache\\huggingface\\datasets\\wikiann\\ru\\1.1.0\\4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000352df40304385a7af5cc8e68304d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wikiann_dataset = load_dataset(\"wikiann\", 'ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f19d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь\n",
    "vocab = Counter()\n",
    "\n",
    "for sent in wikiann_dataset['train']['tokens']:\n",
    "    vocab.update([x.lower() for x in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e68868c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# индексируем слова\n",
    "word2id = {'PAD':0, 'UNK':1}\n",
    "\n",
    "for word in vocab:\n",
    "    word2id[word] = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cdc3962",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {i:word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3209da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переводим тексты в последовательности индексов\n",
    "X = []\n",
    "\n",
    "for sent in wikiann_dataset['train']['tokens']:\n",
    "    tokens = [w.lower() for w in sent]\n",
    "    ids = [word2id.get(token, 1) for token in tokens]\n",
    "    X.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f637bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переводим тексты в последовательности индексов\n",
    "X_test = []\n",
    "\n",
    "for sent in wikiann_dataset['test']['tokens']:\n",
    "    tokens = [w.lower() for w in sent]\n",
    "    ids = [word2id.get(token, 1) for token in tokens]\n",
    "    X_test.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fd637ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = max(len(x) for x in X)\n",
    "\n",
    "# паддинг\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_LEN, padding='post')\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=MAX_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e9bce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2labels = {0:'O', 1:'B-PER', 2:'I-PER', 3:'B-ORG', 4:'I-ORG', 5: 'B-LOC', 6:'I-LOC', 7:'PAD'}\n",
    "label2id = {v:k for k,v in id2labels.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef2bbb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.preprocessing.sequence.pad_sequences(wikiann_dataset['train']['ner_tags'], value=7,\n",
    "                                                  maxlen=MAX_LEN,  padding='post')\n",
    "y_test = tf.keras.preprocessing.sequence.pad_sequences(wikiann_dataset['test']['ner_tags'], value=7,\n",
    "                                                       maxlen=MAX_LEN,  padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac182143",
   "metadata": {},
   "source": [
    "Модель, в которой будут использованы предобученные эмбединги слов и несколько BILSTM слоев. Я взяла 3 слоя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb4ddd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=100)(inputs)\n",
    "\n",
    "lstm_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(embeddings)\n",
    "lstm_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(lstm_1)\n",
    "lstm_3 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(lstm_2)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(lstm_3)\n",
    "\n",
    "bilstm_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "bilstm_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a99845",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_model.fit(X, y, \n",
    "          validation_data=(X_test, y_test),\n",
    "          batch_size=128,\n",
    "         epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf67fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bilstm_model.predict(X_test).argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2d65d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.93      0.95      0.94     40480\n",
      "       B-PER       0.81      0.82      0.81      3542\n",
      "       I-PER       0.94      0.87      0.90      7544\n",
      "       B-ORG       0.77      0.59      0.67      4074\n",
      "       I-ORG       0.88      0.72      0.79      8008\n",
      "       B-LOC       0.60      0.78      0.68      4560\n",
      "       I-LOC       0.60      0.76      0.67      3060\n",
      "         PAD       1.00      1.00      1.00    468732\n",
      "\n",
      "    accuracy                           0.98    540000\n",
      "   macro avg       0.82      0.81      0.81    540000\n",
      "weighted avg       0.98      0.98      0.98    540000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.reshape(-1), pred.reshape(-1), labels=list(id2labels.keys()),\n",
    "                                                                     target_names=list(id2labels.values()),\n",
    "                                                                     zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab87858",
   "metadata": {},
   "source": [
    "Модель, в которой будут использованы предобученные эмбединги слов и несколько BIGRU слоев. Я взяла 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b425de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=100)(inputs)\n",
    "\n",
    "gru_1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(embeddings)\n",
    "gru_2 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(gru_1)\n",
    "gru_3 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(gru_2)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(gru_3)\n",
    "\n",
    "bigru_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "bigru_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b024d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigru_model.fit(X, y, \n",
    "          validation_data=(X_test, y_test),\n",
    "          batch_size=128,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14b7d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bigru_model.predict(X_test).argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85778ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.97      0.89      0.93     40480\n",
      "       B-PER       0.80      0.89      0.84      3542\n",
      "       I-PER       0.90      0.92      0.91      7544\n",
      "       B-ORG       0.71      0.69      0.70      4074\n",
      "       I-ORG       0.86      0.78      0.81      8008\n",
      "       B-LOC       0.55      0.87      0.68      4560\n",
      "       I-LOC       0.63      0.82      0.71      3060\n",
      "         PAD       1.00      1.00      1.00    468732\n",
      "\n",
      "    accuracy                           0.98    540000\n",
      "   macro avg       0.80      0.86      0.82    540000\n",
      "weighted avg       0.98      0.98      0.98    540000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.reshape(-1), pred.reshape(-1), labels=list(id2labels.keys()),\n",
    "                                                                     target_names=list(id2labels.values()),\n",
    "                                                                     zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f52d22ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text, word2id):\n",
    "    # токенизирует и переводит в индексы\n",
    "    tokens = re.findall('\\w+|[^\\w\\s]+', text)\n",
    "    ids = [word2id.get(token.lower(), 1) for token in tokens]\n",
    "    return tokens, ids\n",
    "\n",
    "def pred2tags(pred, id2label, length):\n",
    "    # декодирует индексы в части речи\n",
    "    # length нужно чтобы откидывать паддинги или некорректные предсказания\n",
    "    pred = pred.argmax(2)[0, :length]\n",
    "    labels = [id2label[l] for l in pred]\n",
    "    return labels\n",
    "\n",
    "def label_seq(text, word2id, id2label, max_len, model):\n",
    "    tokens, ids = tokenize(text, word2id)\n",
    "    pred = model.predict(tf.keras.preprocessing.sequence.pad_sequences([ids], \n",
    "                                                                       maxlen=max_len, \n",
    "                                                                       padding='post'))\n",
    "    labels = pred2tags(pred, id2label, len(ids))\n",
    "    \n",
    "    return list(zip(tokens, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a237b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('В', 'O'),\n",
       " ('белом', 'O'),\n",
       " ('плаще', 'O'),\n",
       " ('с', 'O'),\n",
       " ('кровавым', 'O'),\n",
       " ('подбоем', 'O'),\n",
       " ('ранним', 'O'),\n",
       " ('утром', 'O'),\n",
       " ('четырнадцатого', 'O'),\n",
       " ('числа', 'O'),\n",
       " ('весеннего', 'O'),\n",
       " ('месяца', 'O'),\n",
       " ('нисана', 'O'),\n",
       " ('в', 'O'),\n",
       " ('крытую', 'O'),\n",
       " ('колоннаду', 'O'),\n",
       " ('между', 'O'),\n",
       " ('двумя', 'O'),\n",
       " ('крыльями', 'O'),\n",
       " ('дворца', 'B-PER'),\n",
       " ('ирода', 'I-PER'),\n",
       " ('великого', 'I-PER'),\n",
       " ('вышел', 'O'),\n",
       " ('прокуратор', 'O'),\n",
       " ('Иудеи', 'I-PER'),\n",
       " ('Понтий', 'O'),\n",
       " ('Пилат', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_seq('В белом плаще с кровавым подбоем ранним утром четырнадцатого числа весеннего месяца нисана в крытую колоннаду между двумя крыльями дворца ирода великого вышел прокуратор Иудеи Понтий Пилат.', word2id, id2labels, MAX_LEN, bilstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3a7cad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('В', 'O'),\n",
       " ('белом', 'B-ORG'),\n",
       " ('плаще', 'I-ORG'),\n",
       " ('с', 'O'),\n",
       " ('кровавым', 'O'),\n",
       " ('подбоем', 'I-ORG'),\n",
       " ('ранним', 'I-ORG'),\n",
       " ('утром', 'I-ORG'),\n",
       " ('четырнадцатого', 'I-ORG'),\n",
       " ('числа', 'O'),\n",
       " ('весеннего', 'O'),\n",
       " ('месяца', 'O'),\n",
       " ('нисана', 'O'),\n",
       " ('в', 'O'),\n",
       " ('крытую', 'B-LOC'),\n",
       " ('колоннаду', 'O'),\n",
       " ('между', 'O'),\n",
       " ('двумя', 'O'),\n",
       " ('крыльями', 'O'),\n",
       " ('дворца', 'B-PER'),\n",
       " ('ирода', 'I-LOC'),\n",
       " ('великого', 'B-PER'),\n",
       " ('вышел', 'O'),\n",
       " ('прокуратор', 'B-PER'),\n",
       " ('Иудеи', 'B-PER'),\n",
       " ('Понтий', 'I-PER'),\n",
       " ('Пилат', 'I-PER'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_seq('В белом плаще с кровавым подбоем ранним утром четырнадцатого числа весеннего месяца нисана в крытую колоннаду между двумя крыльями дворца ирода великого вышел прокуратор Иудеи Понтий Пилат.', word2id, id2labels, MAX_LEN, bigru_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fce6f9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('От', 'O'),\n",
       " ('другого', 'O'),\n",
       " ('этого', 'O'),\n",
       " ('места', 'O'),\n",
       " ('у', 'O'),\n",
       " ('Никанора', 'B-LOC'),\n",
       " ('Ивановича', 'O'),\n",
       " ('осталось', 'O'),\n",
       " ('в', 'O'),\n",
       " ('воспоминании', 'O'),\n",
       " ('мало', 'O'),\n",
       " ('чего', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_seq('От другого этого места у Никанора Ивановича осталось в воспоминании мало чего.', word2id, id2labels, MAX_LEN, bilstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2571f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('От', 'O'),\n",
       " ('другого', 'O'),\n",
       " ('этого', 'O'),\n",
       " ('места', 'O'),\n",
       " ('у', 'O'),\n",
       " ('Никанора', 'B-LOC'),\n",
       " ('Ивановича', 'O'),\n",
       " ('осталось', 'O'),\n",
       " ('в', 'O'),\n",
       " ('воспоминании', 'B-LOC'),\n",
       " ('мало', 'O'),\n",
       " ('чего', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_seq('От другого этого места у Никанора Ивановича осталось в воспоминании мало чего.', word2id, id2labels, MAX_LEN, bigru_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6aff77d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Маргарита', 'B-PER'),\n",
       " ('подняла', 'I-PER'),\n",
       " ('голову', 'O'),\n",
       " ('к', 'O'),\n",
       " ('луне', 'B-PER'),\n",
       " ('и', 'O'),\n",
       " ('сделала', 'O'),\n",
       " ('задумчивое', 'I-PER'),\n",
       " ('и', 'O'),\n",
       " ('поэтическое', 'O'),\n",
       " ('лицо', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_seq('Маргарита подняла голову к луне и сделала задумчивое и поэтическое лицо.', word2id, id2labels, MAX_LEN, bilstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43863a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Маргарита', 'B-LOC'),\n",
       " ('подняла', 'I-LOC'),\n",
       " ('голову', 'I-LOC'),\n",
       " ('к', 'I-LOC'),\n",
       " ('луне', 'I-LOC'),\n",
       " ('и', 'O'),\n",
       " ('сделала', 'O'),\n",
       " ('задумчивое', 'B-LOC'),\n",
       " ('и', 'O'),\n",
       " ('поэтическое', 'B-LOC'),\n",
       " ('лицо', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_seq('Маргарита подняла голову к луне и сделала задумчивое и поэтическое лицо.', word2id, id2labels, MAX_LEN, bigru_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b9574a",
   "metadata": {},
   "source": [
    "__И BIGRU и BILSTM модели ошибаются при определении сущностей, но BIGRU немного лучше.__\n",
    "__По метрикам - результаты примерно одинаковые, но у BIGRU результаты повыше.__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
