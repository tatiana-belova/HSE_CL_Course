{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d02893",
   "metadata": {},
   "source": [
    "# Домашнее задание № 7\n",
    "\n",
    "__Задание 1. Реализовать алгоритм Леска и проверить его на реальном датасете (8 баллов)__\n",
    "\n",
    "Ворднет можно использовать для дизамбигуации. Самый простой алгоритм дизамбигуации - алгоритм Леска. В нём нужное значение слова находится через пересечение слов контекста, в котором употреблено это слово, с определениями значений слова из ворднета. Значение с максимальным пересечением - нужное.\n",
    "\n",
    "Реализуйте его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "069d301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from string import punctuation\n",
    "import json, os, re, sys\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "morph = MorphAnalyzer()\n",
    "punct = punctuation+'«»—…“”*№–'\n",
    "stops = set(stopwords.words('russian'))\n",
    "\n",
    "def normalize(text):\n",
    "    \n",
    "    words = [token.text.strip(punct) for token in list(razdel_tokenize(text))]\n",
    "    words = [morph.parse(word)[0].normal_form for word in words if word and word not in stops]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cc2ae09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tanbe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43f7be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesk(word, sentence):\n",
    "        \"\"\"Ваш код тут\"\"\"\n",
    "        bestsense = 0\n",
    "        maxoverlap = 0 \n",
    "        orig_set = set(sentence)\n",
    "        wn_sets = []\n",
    "        for i, syns in enumerate(wn.synsets(word)):\n",
    "            wn_sets.append((i,\n",
    "                            set(re.findall(r\"[a-zA-Z]+\", syns.definition()))))\n",
    "\n",
    "        wn_sorted = sorted(wn_sets,\n",
    "                           key=lambda x: len(x[1].intersection(orig_set)),\n",
    "                           reverse=True)\n",
    "        bestsense = wn_sorted[0][0]\n",
    "        return bestsense           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa4dba0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# на вход подается элемент результата работы уже написанной вами функции get_words_in_context\n",
    "lesk('day', 'some point or period in time'.split()) # для примера контекст совпадает с одним из определений\n",
    "# а на выходе индекс подходящего синсета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c53a543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('day.n.01'),\n",
       " Synset('day.n.02'),\n",
       " Synset('day.n.03'),\n",
       " Synset('day.n.04'),\n",
       " Synset('day.n.05'),\n",
       " Synset('day.n.06'),\n",
       " Synset('day.n.07'),\n",
       " Synset('sidereal_day.n.01'),\n",
       " Synset('day.n.09'),\n",
       " Synset('day.n.10')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6279a183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'some point or period in time'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# с помощью этого индекса достаем нужный синсет\n",
    "wn.synsets('day')[1].definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04acfbff",
   "metadata": {},
   "source": [
    "__Проверьте насколько хорошо работает такой метод на датасете из семинара__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46345816",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_wsd = []\n",
    "corpus = open('corpus_wsd_50k.txt').read().split('\\n\\n')\n",
    "for sent in corpus:\n",
    "    corpus_wsd.append([s.split('\\t') for s in sent.split('\\n')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e95dfa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_wsd = corpus_wsd[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49c6516a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', 'how', 'How'],\n",
       " ['long%3:00:02::', 'long', 'long'],\n",
       " ['', 'have', 'has'],\n",
       " ['', 'it', 'it'],\n",
       " ['be%2:42:03::', 'be', 'been'],\n",
       " ['', 'since', 'since'],\n",
       " ['', 'you', 'you'],\n",
       " ['review%2:31:00::', 'review', 'reviewed'],\n",
       " ['', 'the', 'the'],\n",
       " ['objective%1:09:00::', 'objective', 'objectives'],\n",
       " ['', 'of', 'of'],\n",
       " ['', 'you', 'your'],\n",
       " ['benefit%1:21:00::', 'benefit', 'benefit'],\n",
       " ['', 'and', 'and'],\n",
       " ['service%1:04:07::', 'service', 'service'],\n",
       " ['program%1:09:01::', 'program', 'program'],\n",
       " ['', '?', '?']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_wsd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32377c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "counter_true = 0\n",
    "for sent in corpus_wsd[:1000]:\n",
    "    sentence = [w[1] for w in sent]\n",
    "    for word in sent:\n",
    "        if word[0]:\n",
    "            counter += 1\n",
    "            true_syn = wn.lemma_from_key(word[0]).synset()\n",
    "            true = wn.synsets(word[1]).index(true_syn)\n",
    "            pred = lesk(word[1], sentence)\n",
    "            if true == pred:\n",
    "                counter_true += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e2fad1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36496771217712176"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = counter_true / counter\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c6d529",
   "metadata": {},
   "source": [
    "__Процент правильных предсказаний (accuracy) довольно низкий - 36%__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
